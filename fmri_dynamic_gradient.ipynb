{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "\n",
    "\n",
    "GOAL: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Standard Sliding window Dynamic (Visualization)](#sliding)\n",
    "\n",
    "- [Standard Sliding window Dynamic (Analysis)](#slidinganalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_path = \"./data/fmri_compile.csv\"\n",
    "mri_df   = pd.read_csv(mri_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Sliding window Dynamic\n",
    "We don't know the TR but expect it to be around 1 sec and so we have 1 min to be 60 sample points. As advised (at least 1 min) for window size we pick 60 frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"sliding\"></a>\n",
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "\n",
    "filename_movie = 'TC_400_sub-S09_ses-4_Sintel.csv'\n",
    "filename_rest  = 'TC_400_sub-S23_ses-1_Rest.csv'\n",
    "\n",
    "movie_series, movie_df = df_to_timeseries(mri_df, filename_movie)\n",
    "rest_series, rest_df   = df_to_timeseries(mri_df, filename_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable for dFC\n",
    "ws   = 300\n",
    "step = 1 # let's overlap pretty much all for now to see smoothness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Dynamic FC for rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr, nbt = rest_series.T.shape\n",
    "\n",
    "dFC_rest = np.zeros((nbt // step + 1 - ws, nbr,nbr))\n",
    "\n",
    "for c, sidx in enumerate(range(0, nbt, step)):\n",
    "    T = rest_series[sidx:sidx+ws]\n",
    "    if T.shape[0] != ws: \n",
    "        continue\n",
    "    correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "    dFC_rest[c] = correlation_measure.fit_transform([T])[0]\n",
    "\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "ref_FC_rest = correlation_measure.fit_transform([rest_series])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Dynamic FC for movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr, nbt = movie_series.T.shape\n",
    "\n",
    "dFC_movie = np.zeros((nbt // step + 1 - ws, nbr,nbr))\n",
    "\n",
    "for c, sidx in enumerate(range(0, nbt, step)):\n",
    "    T = movie_series[sidx:sidx+ws]\n",
    "    if T.shape[0] != ws: \n",
    "        continue\n",
    "    correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "    dFC_movie[c] = correlation_measure.fit_transform([T])[0]\n",
    "\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "ref_FC_movie = correlation_measure.fit_transform([movie_series])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [00:02<00:00, 55.25it/s]\n",
      "100%|██████████| 412/412 [00:07<00:00, 54.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from brainspace.gradient import GradientMaps\n",
    "\n",
    "embedding  = \"dm\" # diffusion map\n",
    "aff_kernel = \"pearson\" #affinity matrix kernel\n",
    "align_meth = \"procrustes\"\n",
    "nb_comp    = 2\n",
    "\n",
    "gref_rest = GradientMaps(n_components=nb_comp, approach=embedding, kernel=aff_kernel)\n",
    "gref_rest.fit(ref_FC_rest)\n",
    "\n",
    "gref_movie = GradientMaps(n_components=nb_comp, approach=embedding, kernel=aff_kernel)\n",
    "gref_movie.fit(ref_FC_movie)\n",
    "\n",
    "# Computing Rest Gradients\n",
    "G_rest  = []\n",
    "for widx in tqdm(range(0, len(dFC_rest))):\n",
    "\n",
    "    galign = GradientMaps(n_components=nb_comp, kernel=aff_kernel, approach=embedding, alignment=align_meth)\n",
    "    galign.fit(dFC_rest[widx], reference=gref_rest.gradients_)\n",
    "    G_rest.append(galign.gradients_)\n",
    "\n",
    "# Computing Movie Gradients\n",
    "G_movie = []\n",
    "for widx in tqdm(range(0, len(dFC_movie))):\n",
    "\n",
    "    galign = GradientMaps(n_components=nb_comp, kernel=aff_kernel, approach=embedding, alignment=align_meth)\n",
    "    galign.fit(dFC_movie[widx], reference=gref_movie.gradients_)\n",
    "    G_movie.append(galign.gradients_)\n",
    "\n",
    "G_rest  = np.asarray(G_rest)\n",
    "G_movie = np.asarray(G_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_region_movie = { k: movie_df[movie_df.vindex == k]['partial_region'].iloc[0]\n",
    "                    for k in movie_df['vindex'].unique()}\n",
    "partial_region_rest  = { k: rest_df[rest_df.vindex == k]['partial_region'].iloc[0]\n",
    "                    for k in rest_df['vindex'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161/161 [01:00<00:00,  2.67it/s]\n",
      "100%|██████████| 412/412 [02:27<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "coloring  = [partial_region_movie[i] for i in range(400)]\n",
    "ts = ['rest', 'movie']\n",
    "\n",
    "gs = [G_rest, G_movie]\n",
    "\n",
    "for i in range(2):\n",
    "    for j in tqdm(range(len(gs[i]))):\n",
    "        tmp_df = {\"G1\":gs[i][j][:,0] , \"G2\": gs[i][j][:,1], \"region\": coloring}\n",
    "        ax     = sns.jointplot(data=tmp_df, x=\"G1\", y=\"G2\", \n",
    "                    hue=\"region\", height=5, \n",
    "                    xlim=(gs[i][:,0].min()*1.5,gs[i][:,0].max()*1.5), \n",
    "                    ylim=(gs[i][:,1].min()*1.5,gs[i][:,1].max()*1.5))\n",
    "        ax.fig.suptitle(\"Gradients's closenedness plot ({})\".format(ts[i]))\n",
    "        legend_properties = {'weight':'bold','size':6}\n",
    "        ax.ax_joint.legend(prop=legend_properties,loc='upper right')\n",
    "        ax.savefig(\"./media/gradient_plots/{}_{}.jpg\".format(ts[i],j))\n",
    "\n",
    "        #this is the line to be added to avoid showing all the list of plots\n",
    "        plt.close(\"all\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"{}/master_project/brainspace_demo/media/gradient_plots\".format(ROOT)\n",
    "\n",
    "# # reorder saved images path\n",
    "# rest_path  = loadimg_in_order([r for r in os.listdir(path) if 'rest' in r])\n",
    "# movie_path = loadimg_in_order([m for m in os.listdir(path) if 'movie' in m])\n",
    "\n",
    "# rest_array  = [cv2.imread(path+'/'+filename)[:,:,::-1] for filename in rest_path]\n",
    "# movie_array = [cv2.imread(path+'/'+filename)[:,:,::-1] for filename in movie_path]\n",
    "\n",
    "# img2video(rest_array, 3, outpath_name='./media/rest_plots.mp4')\n",
    "# img2video(movie_array, 3, outpath_name='./media/movie_plots.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"slidinganalysis\"></a>\n",
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = [G_rest, G_movie]\n",
    "tmp_df = pd.DataFrame.from_dict(tmp_df) # defined from previous plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Vis', 'SomMot', 'DorsAttn', 'SalVentAttn', 'Limbic', 'Cont',\n",
       "       'Default'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df.region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "             13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "             26,  27,  28,  29,  30, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "            208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "            221, 222, 223, 224, 225, 226, 227, 228, 229],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tmp_df[tmp_df.region=='Vis'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.24564695, 11.07860739,  4.11536152, ...,  4.04292376,\n",
       "        10.03191294,  8.840907  ],\n",
       "       [10.977097  , 12.53246023,  4.92668605, ...,  3.89637712,\n",
       "        11.05397252,  9.75068104],\n",
       "       [11.51861767, 12.91690661,  4.79440588, ...,  4.22275815,\n",
       "        11.15807691,  9.88467771],\n",
       "       ...,\n",
       "       [10.08068345,  9.88693506,  7.72073112, ..., -0.93709564,\n",
       "         7.61615117,  6.9592662 ],\n",
       "       [10.47864607, 10.13122946,  8.18095511, ..., -1.5393993 ,\n",
       "         7.53040754,  6.90201834],\n",
       "       [10.57631356, 10.05065518,  8.00377123, ..., -1.04507373,\n",
       "         7.57874089,  6.93131907]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_rest[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 400, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_rest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('brain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ec5124dab3befe0b36c3911d00ea5bb875e1c7733f5b9dfa3353c27fabcb1db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
