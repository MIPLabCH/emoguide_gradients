{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2c2489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7687802f",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Timeseries Comparison](#comparison)\n",
    "- [GLM](#weightings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f96440f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"comparison\"></a>\n",
    "### Timeseries Comparison \n",
    "Comparison between item timeseries and centroid of region timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a006dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loading Gradient Example\n",
    "networks = list(index2region.keys())\n",
    "moviename = 'Sintel'\n",
    "\n",
    "G_movie, varM = load('./resources/dynamic_grad/group_level414/{}_40_grad.pkl'.format(moviename))\n",
    "\n",
    "# 2. Loading Matching Emotion Track\n",
    "full_df  = pd.read_csv('./data/emoFiles/emotion_compile.csv')\n",
    "emo_df   = full_df[full_df['filename']=='W_{}13.csv'.format(moviename)]\n",
    "other_df = full_df[full_df['filename']!='W_{}13.csv'.format(moviename)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f912ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = ['Anger','Guilt','WarmHeartedness', \\\n",
    "             'Disgust','Happiness','Fear','Contempt','Anxiety', \\\n",
    "             'Satisfaction','Shame','Surprise','Love','Sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34788fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [03:05<00:00, 26.49s/it]\n",
      "100%|██████████| 7/7 [03:02<00:00, 26.03s/it]\n",
      "100%|██████████| 7/7 [03:02<00:00, 26.05s/it]\n",
      "100%|██████████| 7/7 [03:01<00:00, 25.96s/it]\n",
      " 29%|██▊       | 2/7 [01:04<02:40, 32.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/michaelc.c.h/Desktop/EPFL/master_project/brainspace_demo/15_fmri_emotion_networks.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelc.c.h/Desktop/EPFL/master_project/brainspace_demo/15_fmri_emotion_networks.ipynb#W4sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m smoothened \u001b[39m=\u001b[39m overlap_add(emo_series, smfactor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelc.c.h/Desktop/EPFL/master_project/brainspace_demo/15_fmri_emotion_networks.ipynb#W4sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m z2   \u001b[39m=\u001b[39m zscore(smoothened[:z1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/michaelc.c.h/Desktop/EPFL/master_project/brainspace_demo/15_fmri_emotion_networks.ipynb#W4sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m _, nscore, corr \u001b[39m=\u001b[39m moviemix_stat_test(z1, z2, concat_other)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelc.c.h/Desktop/EPFL/master_project/brainspace_demo/15_fmri_emotion_networks.ipynb#W4sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m nscores[\u001b[39m4\u001b[39m, idx,jdx] \u001b[39m=\u001b[39m nscore\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelc.c.h/Desktop/EPFL/master_project/brainspace_demo/15_fmri_emotion_networks.ipynb#W4sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m scores[\u001b[39m4\u001b[39m, idx,jdx]  \u001b[39m=\u001b[39m corr\n",
      "File \u001b[0;32m~/Desktop/EPFL/master_project/brainspace_demo/src/stats_utils.py:87\u001b[0m, in \u001b[0;36mmoviemix_stat_test\u001b[0;34m(totest, mainseries, mixseries)\u001b[0m\n\u001b[1;32m     85\u001b[0m b \u001b[39m=\u001b[39m mixseries[i:i\u001b[39m+\u001b[39m\u001b[39mlen\u001b[39m(totest)]\n\u001b[1;32m     86\u001b[0m b \u001b[39m=\u001b[39m overlap_add(b, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m a, b \u001b[39m=\u001b[39m zscore(totest), zscore(b)\n\u001b[1;32m     88\u001b[0m corr, _,_ \u001b[39m=\u001b[39m correlation_search(a,b, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     89\u001b[0m ndistrib\u001b[39m.\u001b[39mappend(corr)\n",
      "File \u001b[0;32m~/Desktop/EPFL/master_project/brainspace_demo/src/utils.py:86\u001b[0m, in \u001b[0;36mzscore\u001b[0;34m(signal, ret_param)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mzscore\u001b[39m(signal, ret_param\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     70\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    Information:\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m    ------------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m    score::[ndarray<float>]\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m    \n\u001b[0;32m---> 86\u001b[0m     m, s  \u001b[39m=\u001b[39m signal\u001b[39m.\u001b[39mmean(), signal\u001b[39m.\u001b[39;49mstd()\n\u001b[1;32m     87\u001b[0m     score \u001b[39m=\u001b[39m (signal \u001b[39m-\u001b[39m m) \u001b[39m/\u001b[39m s\n\u001b[1;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m ret_param:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid for each network of correlation with emotions\n",
    "grad_idx = 0\n",
    "smfactor = 1\n",
    "tolshift = 0\n",
    "\n",
    "n = len(networks)\n",
    "m = len(select)\n",
    "\n",
    "pairs = [(\"Vis\", \"Default\"), (\"SomMot\", \"Default\"), \n",
    "        (\"SomMot\", \"Vis\"), (\"DorsAttn\", \"SalVentAttn\"),\n",
    "        (\"DorsAttn\", \"Default\"), (\"Limbic\", \"Default\"), (\"Cont\", \"Default\")]\n",
    "nb_metric = 6\n",
    "scores  = np.zeros((nb_metric, n,m))\n",
    "nscores = np.zeros((nb_metric, n,m))\n",
    "\n",
    "# METRIC 1\n",
    "for idx, pair in enumerate(tqdm(pairs)):\n",
    "    p1,p2 = pair\n",
    "    y = np.asarray([networks_distance(G_movie[t], G_movie[t], p1, p2) \n",
    "                    for t in range(len(G_movie))])\n",
    "    z1 = zscore(y)\n",
    "    for jdx, emotion in enumerate(select):\n",
    "        concat_other = np.array(other_df[other_df.item == emotion]['score'])\n",
    "        emo_series = np.array(emo_df[emo_df.item==emotion]['score'])\n",
    "        smoothened = overlap_add(emo_series, smfactor)\n",
    "        z2   = zscore(smoothened[:z1.shape[0]])\n",
    "\n",
    "        _, nscore, corr = moviemix_stat_test(z1, z2, concat_other)\n",
    "        nscores[0, idx,jdx] = nscore\n",
    "        scores[0, idx,jdx]  = corr           \n",
    "\n",
    "# # METRIC 2\n",
    "# for idx, R in enumerate(tqdm(networks)):\n",
    "#     y  = network_variance(G_movie, R, grad_idx)\n",
    "#     z1 = zscore(y)\n",
    "\n",
    "#     for jdx, emotion in enumerate(select):\n",
    "#         concat_other = np.array(other_df[other_df.item == emotion]['score'])\n",
    "#         emo_series = np.array(emo_df[emo_df.item==emotion]['score'])\n",
    "#         smoothened = overlap_add(emo_series, smfactor)\n",
    "#         z2   = zscore(smoothened[:z1.shape[0]])\n",
    "\n",
    "#         _, nscore, corr = moviemix_stat_test(z1, z2, concat_other)\n",
    "#         nscores[1, idx,jdx] = nscore\n",
    "#         scores[1, idx,jdx]  = corr        \n",
    "    \n",
    "# METRIC 3\n",
    "for idx, R in enumerate(tqdm(networks)):\n",
    "    y  = np.asarray([network_volume(G_movie[t], R) \n",
    "                    for t in range(len(G_movie))])\n",
    "    z1 = zscore(y)\n",
    "\n",
    "    for jdx, emotion in enumerate(select):\n",
    "        concat_other = np.array(other_df[other_df.item == emotion]['score'])\n",
    "        emo_series = np.array(emo_df[emo_df.item==emotion]['score'])\n",
    "        smoothened = overlap_add(emo_series, smfactor)\n",
    "        z2   = zscore(smoothened[:z1.shape[0]])\n",
    "\n",
    "        _, nscore, corr = moviemix_stat_test(z1, z2, concat_other)\n",
    "        nscores[2, idx,jdx] = nscore\n",
    "        scores[2, idx,jdx]  = corr\n",
    "\n",
    "# METRIC 4\n",
    "for idx, R in enumerate(tqdm(networks)-4):\n",
    "    y  = varM[:,idx]\n",
    "    z1 = zscore(y)\n",
    "\n",
    "    for jdx, emotion in enumerate(select):\n",
    "        concat_other = np.array(other_df[other_df.item == emotion]['score'])\n",
    "        emo_series = np.array(emo_df[emo_df.item==emotion]['score'])\n",
    "        smoothened = overlap_add(emo_series, smfactor)\n",
    "        z2   = zscore(smoothened[:z1.shape[0]])\n",
    "\n",
    "        _, nscore, corr = moviemix_stat_test(z1, z2, concat_other)\n",
    "        nscores[3, idx,jdx] = nscore\n",
    "        scores[3, idx,jdx]  = corr\n",
    "\n",
    "\n",
    "# METRIC 5 first 7 region of subcortical\n",
    "for idx, R in enumerate(tqdm(networks)):\n",
    "    tmpA = G_movie[:, 400+idx][:-1]\n",
    "    tmpB = G_movie[:, 400+idx][1:]\n",
    "\n",
    "    y  = np.asarray([ points_distance(tmpA[pidx], tmpB[pidx], pmethod=\"L2\") \n",
    "                        for pidx in range(len(tmpA))])\n",
    "    z1 = zscore(y)\n",
    "\n",
    "    for jdx, emotion in enumerate(select):\n",
    "        concat_other = np.array(other_df[other_df.item == emotion]['score'])\n",
    "        emo_series = np.array(emo_df[emo_df.item==emotion]['score'])\n",
    "        smoothened = overlap_add(emo_series, smfactor)\n",
    "        z2   = zscore(smoothened[:z1.shape[0]])\n",
    "\n",
    "        _, nscore, corr = moviemix_stat_test(z1, z2, concat_other)\n",
    "        nscores[4, idx,jdx] = nscore\n",
    "        scores[4, idx,jdx]  = corr\n",
    "\n",
    "# METRIC 6 second set of 7 region of subcortical\n",
    "for idx, R in enumerate(tqdm(networks)):\n",
    "    tmpA = G_movie[:, 407+idx][:-1]\n",
    "    tmpB = G_movie[:, 407+idx][1:]\n",
    "\n",
    "    y  = np.asarray([ points_distance(tmpA[pidx], tmpB[pidx], pmethod=\"L2\") \n",
    "                        for pidx in range(len(tmpA))])\n",
    "    z1 = zscore(y)\n",
    "\n",
    "    for jdx, emotion in enumerate(select):\n",
    "        concat_other = np.array(other_df[other_df.item == emotion]['score'])\n",
    "        emo_series = np.array(emo_df[emo_df.item==emotion]['score'])\n",
    "        smoothened = overlap_add(emo_series, smfactor)\n",
    "        z2   = zscore(smoothened[:z1.shape[0]])\n",
    "\n",
    "        _, nscore, corr = moviemix_stat_test(z1, z2, concat_other)\n",
    "        nscores[5, idx,jdx] = nscore\n",
    "        scores[5, idx,jdx]  = corr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb06e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('brain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ec5124dab3befe0b36c3911d00ea5bb875e1c7733f5b9dfa3353c27fabcb1db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
